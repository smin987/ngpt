{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EX 5.0 ConversationBufferMemory\n",
    "\n",
    "OpenAI에서 지원하는 기본 API는 langchaine없이 사용가능 하지만 메모리를 지원하지 않는다.  \n",
    "메모리를 설정해 주지않으면 챗봇은 대화를 기억할수 없기 때문에 이어지는 질문을 이해하지 못한다.\n",
    "\n",
    "Langchaine 에는 5가지 메모리가 있는데 각각의 장단점이 있다.\n",
    "\n",
    "> 1.  ConversationBufferMemory - 대화 내용 전체를 저장\n",
    "> 2.  ConversationBufferWindowMemory - 대화 내용 일부를 저장(설정가능)\n",
    "> 3.  ConversationSummaryMemory - 대화 내용을 자체적으로 요약해서 저장\n",
    "> 4.  ConversationSummaryBufferMemory -설정한 메시지 갯수 초과시 오래된 메시지들은 요약\n",
    "> 5.  ConversationKGMemory -대화의 내용을 확인해서 객체의 주요한 특징을 기억한다.\n",
    "\n",
    "1. ConversationBufferMemory\n",
    "   - 대화 내용 전체를 저장하는 메모리\n",
    "   - 대화 내용이 길어지면 메모리가 커지므로 비효율적인 경우가 많다.\n",
    "     - 사용자와 대화시 처음부터의 지금까지의 대화를 계속 챗봇에게 전달하는데, 대화가 길어질수록 전달하는 양이 점점 늘어나게 된다.\n",
    "\n",
    "- 예측이나 텍스트 자동완성을 위한 text completion에 유용.\n",
    "- 채팅 모델과 작업을 할시 ai, human message 모두 필요\n",
    "\n",
    "tip) 모든 메모리는 save_context, load_memory_variables 라는 항수를 가지고 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# chat model을 위한게 아니라면 return_messages=False로 한다.\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi!\"}, {\"output\": \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EX 5.1 ConversationBufferWindowMemory\n",
    "\n",
    "2. ConversationBufferWindowMemory\n",
    "   - 대화의 특정 부분만을 저장하는 메모리\n",
    "     - 최근 5개의 대화를 저장하도록 설정하면 6번째 대화시 가장 오래된 대화가 사라짐\n",
    "   - 단점은 챗봇이 전체 대화가 아닌 최근 대화에만 집중하게 됨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(return_messages=True, k=4)\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EX 5.2 ConversationSummaryMemory\n",
    "\n",
    "3. ConversationSummaryMemory\n",
    "   - Message를 그대로 저장하는 것이 아니라 coversation의 요약을 자체적으로 해주는 메모리\n",
    "     - 초기에는 이전보다 더 많은 토큰과 저장공간을 차지함\n",
    "     - 대화의 내용이 많아질수록 효과가 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Sungmin, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human introduces themselves as Sungmin from South Korea. The AI thinks it is cool and wishes it could go to South Korea because it is so pretty and expresses its desire to visit.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")\n",
    "\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EX 5.3 ConversationSummaryBufferMemory\n",
    "\n",
    "4. ConversationSummaryBufferMemory\n",
    "   - ConversationSummaryMemory, ConversationBufferMemory의 결합\n",
    "     - 메모리에 보내온 메시지를 설정한 갯수 만큼 저장\n",
    "     - 메모리에 저장된 메시지가 설정한 갯수 초과시 오래된 메시지들은 요약해서 정리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Sungmin, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=40,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Sungmin, I live in South Korea\", \"Wow that is so cool!\")\n",
    "\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human introduces themselves as Sungmin and mentions that they live in South Korea.'),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EX 5.4 ConversationKGMemory\n",
    "\n",
    "5. ConversationKnowledgeGraphMemory\n",
    "   - 대화 중 객체의 Knowledge Graph를 만든다.\n",
    "   - 즉 대화의 내용을 확인해서 객체의 주요한 특징을 기억한다.\n",
    "\n",
    "> Knowledge Graph : 연결된 데이터의 네트워크를 통해 사물 간의 관계와 속성을 표현하는 그래프 기반의 구조\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Sungmin, I live in South Korea\", \"Wow that is so cool!\")\n",
    "\n",
    "# KG에서 히스토리를 가지고오지 않고 객체를 가지고 오기 때문에 get_history에 내용이 담기지 않는다.\n",
    "# get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On Sungmin: Sungmin is a person. Sungmin lives in South Korea.')]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"Who is Sungmin\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ngpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
